{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Lab: Neural Networks for Handwritten Digit Recognition, Binary\n",
    "\n",
    "In this exercise, you will use a neural network to recognize the hand-written digits zero and one.\n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Neural Networks](#2)\n",
    "  - [ 2.1 Problem Statement](#2.1)\n",
    "  - [ 2.2 Dataset](#2.2)\n",
    "  - [ 2.3 Model representation](#2.3)\n",
    "  - [ 2.4 Tensorflow Model Implementation](#2.4)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 2.5 NumPy Model Implementation (Forward Prop in NumPy)](#2.5)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 2.6 Vectorized NumPy Model Implementation (Optional)](#2.6)\n",
    "    - [ Exercise 3](#ex03)\n",
    "  - [ 2.7 Congratulations!](#2.7)\n",
    "  - [ 2.8 NumPy Broadcasting Tutorial (Optional)](#2.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment.\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a popular library to plot graphs in Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) a popular platform for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:57.099021Z",
     "start_time": "2024-10-19T08:45:57.092933Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from autils import *\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow and Keras**  \n",
    "Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by François Chollet that creates a simple, layer-centric interface to Tensorflow. This course will be using the Keras interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Neural Networks\n",
    "\n",
    "In Course 1, you implemented logistic regression. This was extended to handle non-linear boundaries using polynomial regression. For even more complex scenarios such as image recognition, neural networks are preferred.\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Problem Statement\n",
    "\n",
    "In this exercise, you will use a neural network to recognize two handwritten digits, zero and one. This is a binary classification task. Automated handwritten digit recognition is widely used today - from recognizing zip codes (postal codes) on mail envelopes to recognizing amounts written on bank checks. You will extend this network to recognize all 10 digits (0-9) in a future assignment. \n",
    "\n",
    "This exercise will show you how the methods you have learned can be used for this classification task.\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Dataset\n",
    "\n",
    "You will start by loading the dataset for this task. \n",
    "- The `load_data()` function shown below loads the data into variables `X` and `y`\n",
    "\n",
    "\n",
    "- The data set contains 1000 training examples of handwritten digits $^1$, here limited to zero and one.  \n",
    "\n",
    "    - Each training example is a 20-pixel x 20-pixel grayscale image of the digit. \n",
    "        - Each pixel is represented by a floating-point number indicating the grayscale intensity at that location. \n",
    "        - The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector. \n",
    "        - Each training example becomes a single row in our data matrix `X`. \n",
    "        - This gives us a 1000 x 400 matrix `X` where every row is a training example of a handwritten digit image.\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- The second part of the training set is a 1000 x 1 dimensional vector `y` that contains labels for the training set\n",
    "    - `y = 0` if the image is of the digit `0`, `y = 1` if the image is of the digit `1`.\n",
    "\n",
    "$^1$<sub> This is a subset of the MNIST handwritten digit dataset (http://yann.lecun.com/exdb/mnist/)</sub>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:57.286306Z",
     "start_time": "2024-10-19T08:45:57.273286Z"
    }
   },
   "source": [
    "# load dataset\n",
    "X, y = load_data()\n",
    "y"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.1\"></a>\n",
    "#### 2.2.1 View the variables\n",
    "Let's get more familiar with your dataset.  \n",
    "- A good place to start is to print out each variable and see what it contains.\n",
    "\n",
    "The code below prints elements of the variables `X` and `y`.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:57.302257Z",
     "start_time": "2024-10-19T08:45:57.296233Z"
    }
   },
   "source": [
    "print ('The first element of X is: ', X[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.56059680e-06\n",
      "  1.94035948e-06 -7.37438725e-04 -8.13403799e-03 -1.86104473e-02\n",
      " -1.87412865e-02 -1.87572508e-02 -1.90963542e-02 -1.64039011e-02\n",
      " -3.78191381e-03  3.30347316e-04  1.27655229e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.16421569e-04  1.20052179e-04\n",
      " -1.40444581e-02 -2.84542484e-02  8.03826593e-02  2.66540339e-01\n",
      "  2.73853746e-01  2.78729541e-01  2.74293607e-01  2.24676403e-01\n",
      "  2.77562977e-02 -7.06315478e-03  2.34715414e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.28335523e-17 -3.26286765e-04 -1.38651604e-02\n",
      "  8.15651552e-02  3.82800381e-01  8.57849775e-01  1.00109761e+00\n",
      "  9.69710638e-01  9.30928598e-01  1.00383757e+00  9.64157356e-01\n",
      "  4.49256553e-01 -5.60408259e-03 -3.78319036e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10620915e-06\n",
      "  4.36410675e-04 -3.95509940e-03 -2.68537241e-02  1.00755014e-01\n",
      "  6.42031710e-01  1.03136838e+00  8.50968614e-01  5.43122379e-01\n",
      "  3.42599738e-01  2.68918777e-01  6.68374643e-01  1.01256958e+00\n",
      "  9.03795598e-01  1.04481574e-01 -1.66424973e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.59875260e-05\n",
      " -3.10606987e-03  7.52456076e-03  1.77539831e-01  7.92890120e-01\n",
      "  9.65626503e-01  4.63166079e-01  6.91720680e-02 -3.64100526e-03\n",
      " -4.12180405e-02 -5.01900656e-02  1.56102907e-01  9.01762651e-01\n",
      "  1.04748346e+00  1.51055252e-01 -2.16044665e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.87012352e-05 -6.40931373e-04\n",
      " -3.23305249e-02  2.78203465e-01  9.36720163e-01  1.04320956e+00\n",
      "  5.98003217e-01 -3.59409041e-03 -2.16751770e-02 -4.81021923e-03\n",
      "  6.16566793e-05 -1.23773318e-02  1.55477482e-01  9.14867477e-01\n",
      "  9.20401348e-01  1.09173902e-01 -1.71058007e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.56250000e-04 -4.27724104e-04 -2.51466503e-02\n",
      "  1.30532561e-01  7.81664862e-01  1.02836583e+00  7.57137601e-01\n",
      "  2.84667194e-01  4.86865128e-03 -3.18688725e-03  0.00000000e+00\n",
      "  8.36492601e-04 -3.70751123e-02  4.52644165e-01  1.03180133e+00\n",
      "  5.39028101e-01 -2.43742611e-03 -4.80290033e-03  0.00000000e+00\n",
      "  0.00000000e+00 -7.03635621e-04 -1.27262443e-02  1.61706648e-01\n",
      "  7.79865383e-01  1.03676705e+00  8.04490400e-01  1.60586724e-01\n",
      " -1.38173339e-02  2.14879493e-03 -2.12622549e-04  2.04248366e-04\n",
      " -6.85907627e-03  4.31712963e-04  7.20680947e-01  8.48136063e-01\n",
      "  1.51383408e-01 -2.28404366e-02  1.98971950e-04  0.00000000e+00\n",
      "  0.00000000e+00 -9.40410539e-03  3.74520505e-02  6.94389110e-01\n",
      "  1.02844844e+00  1.01648066e+00  8.80488426e-01  3.92123945e-01\n",
      " -1.74122413e-02 -1.20098039e-04  5.55215142e-05 -2.23907271e-03\n",
      " -2.76068376e-02  3.68645493e-01  9.36411169e-01  4.59006723e-01\n",
      " -4.24701797e-02  1.17356610e-03  1.88929739e-05  0.00000000e+00\n",
      "  0.00000000e+00 -1.93511951e-02  1.29999794e-01  9.79821705e-01\n",
      "  9.41862388e-01  7.75147704e-01  8.73632241e-01  2.12778350e-01\n",
      " -1.72353349e-02  0.00000000e+00  1.09937426e-03 -2.61793751e-02\n",
      "  1.22872879e-01  8.30812662e-01  7.26501773e-01  5.24441863e-02\n",
      " -6.18971913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.36563862e-03  3.68349741e-02  6.99079299e-01\n",
      "  1.00293583e+00  6.05704402e-01  3.27299224e-01 -3.22099249e-02\n",
      " -4.83053002e-02 -4.34069138e-02 -5.75151144e-02  9.55674190e-02\n",
      "  7.26512627e-01  6.95366966e-01  1.47114481e-01 -1.20048679e-02\n",
      " -3.02798203e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.76572712e-04 -6.51415556e-03  1.17339359e-01\n",
      "  4.21948410e-01  9.93210937e-01  8.82013974e-01  7.45758734e-01\n",
      "  7.23874268e-01  7.23341725e-01  7.20020340e-01  8.45324959e-01\n",
      "  8.31859739e-01  6.88831870e-02 -2.77765012e-02  3.59136710e-04\n",
      "  7.14869281e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.53186275e-04  3.17353553e-04 -2.29167177e-02\n",
      " -4.14402914e-03  3.87038450e-01  5.04583435e-01  7.74885876e-01\n",
      "  9.90037446e-01  1.00769478e+00  1.00851440e+00  7.37905042e-01\n",
      "  2.15455291e-01 -2.69624864e-02  1.32506127e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36366422e-04\n",
      " -2.26031454e-03 -2.51994485e-02 -3.73889910e-02  6.62121228e-02\n",
      "  2.91134498e-01  3.23055726e-01  3.06260315e-01  8.76070942e-02\n",
      " -2.50581917e-02  2.37438725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  6.20939216e-18  6.72618320e-04 -1.13151411e-02\n",
      " -3.54641066e-02 -3.88214912e-02 -3.71077412e-02 -1.33524928e-02\n",
      "  9.90964718e-04  4.89176960e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:57.333694Z",
     "start_time": "2024-10-19T08:45:57.317075Z"
    }
   },
   "source": [
    "print ('The first element of y is: ', y[0,0])\n",
    "print ('The last element of y is: ', y[-1,0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of y is:  0\n",
      "The last element of y is:  1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.2\"></a>\n",
    "#### 2.2.2 Check the dimensions of your variables\n",
    "\n",
    "Another way to get familiar with your data is to view its dimensions. Please print the shape of `X` and `y` and see how many training examples you have in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:57.381142Z",
     "start_time": "2024-10-19T08:45:57.368786Z"
    }
   },
   "source": [
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1000, 400)\n",
      "The shape of y is: (1000, 1)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_89367_2.2.3\"></a>\n",
    "#### 2.2.3 Visualizing the Data\n",
    "\n",
    "You will begin by visualizing a subset of the training set. \n",
    "- In the cell below, the code randomly selects 64 rows from `X`, maps each row back to a 20 pixel by 20 pixel grayscale image and displays the images together. \n",
    "- The label for each image is displayed above the image "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:58.883753Z",
     "start_time": "2024-10-19T08:45:57.383316Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(y[random_index,0])\n",
    "    ax.set_axis_off()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 64 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Model representation\n",
    "\n",
    "The neural network you will use in this assignment is shown in the figure below. \n",
    "- This has three dense layers with sigmoid activations.\n",
    "    - Recall that our inputs are pixel values of digit images.\n",
    "    - Since the images are of size $20\\times20$, this gives us $400$ inputs  \n",
    "    \n",
    "<img src=\"images/C2_W1_Assign1.PNG\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The parameters have dimensions that are sized for a neural network with $25$ units in layer 1, $15$ units in layer 2 and $1$ output unit in layer 3. \n",
    "\n",
    "    - Recall that the dimensions of these parameters are determined as follows:\n",
    "        - If network has $s_{in}$ units in a layer and $s_{out}$ units in the next layer, then \n",
    "            - $W$ will be of dimension $s_{in} \\times s_{out}$.\n",
    "            - $b$ will a vector with $s_{out}$ elements\n",
    "  \n",
    "    - Therefore, the shapes of `W`, and `b`,  are \n",
    "        - layer1: The shape of `W1` is (400, 25) and the shape of `b1` is (25,)\n",
    "        - layer2: The shape of `W2` is (25, 15) and the shape of `b2` is: (15,)\n",
    "        - layer3: The shape of `W3` is (15, 1) and the shape of `b3` is: (1,)\n",
    ">**Note:** The bias vector `b` could be represented as a 1-D (n,) or 2-D (n,1) array. Tensorflow utilizes a 1-D representation and this lab will maintain that convention. \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Tensorflow Model Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow models are built layer by layer. A layer's input dimensions ($s_{in}$ above) are calculated for you. You specify a layer's *output dimensions* and this determines the next layer's input dimension. The input dimension of the first layer is derived from the size of the input data specified in the `model.fit` statment below. \n",
    ">**Note:** It is also possible to add an input layer that specifies the input dimension of the first layer. For example:  \n",
    "`tf.keras.Input(shape=(400,)),    #specify input shape`  \n",
    "We will include that here to illuminate some model sizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "Below, using Keras [Sequential model](https://keras.io/guides/sequential_model/) and [Dense Layer](https://keras.io/api/layers/core_layers/dense/) with a sigmoid activation to construct the network described above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:58.914779Z",
     "start_time": "2024-10-19T08:45:58.885753Z"
    }
   },
   "source": [
    "# UNQ_C1\n",
    "# GRADED CELL: Sequential model\n",
    "\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(400,)),    #specify input size\n",
    "        ### START CODE HERE ### \n",
    "        tf.keras.layers.Dense(25, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(15, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"my_model\" \n",
    ")                            \n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:58.929753Z",
     "start_time": "2024-10-19T08:45:58.916778Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"my_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m25\u001B[0m)             │        \u001B[38;5;34m10,025\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │           \u001B[38;5;34m390\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m16\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,025</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m10,431\u001B[0m (40.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,431</span> (40.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m10,431\u001B[0m (40.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,431</span> (40.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Expected Output (Click to Expand) </b></font></summary>\n",
    "The `model.summary()` function displays a useful summary of the model. Because we have specified an input layer size, the shape of the weight and bias arrays are determined and the total number of parameters per layer can be shown. Note, the names of the layers may vary as they are auto-generated.  \n",
    "    \n",
    "    \n",
    "```\n",
    "Model: \"my_model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 25)                10025     \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 15)                390       \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 16        \n",
    "=================================================================\n",
    "Total params: 10,431\n",
    "Trainable params: 10,431\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "As described in the lecture:\n",
    "    \n",
    "```python\n",
    "model = Sequential(                      \n",
    "    [                                   \n",
    "        tf.keras.Input(shape=(400,)),    # specify input size (optional)\n",
    "        Dense(25, activation='sigmoid'), \n",
    "        Dense(15, activation='sigmoid'), \n",
    "        Dense(1,  activation='sigmoid')  \n",
    "    ], name = \"my_model\"                                    \n",
    ")                                       \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T08:45:58.961205Z",
     "start_time": "2024-10-19T08:45:58.930753Z"
    }
   },
   "source": [
    "# UNIT TESTS\n",
    "from public_tests import * \n",
    "\n",
    "test_c1(model)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer my_model has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# UNIT TESTS\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpublic_tests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m \n\u001B[1;32m----> 4\u001B[0m \u001B[43mtest_c1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Files\\GithubResp\\Machine-Learning-Specialization-Coursera\\C2 - Advanced Learning Algorithms\\week1\\C2W1A1\\public_tests.py:10\u001B[0m, in \u001B[0;36mtest_c1\u001B[1;34m(target)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest_c1\u001B[39m(target):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target\u001B[38;5;241m.\u001B[39mlayers) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m, \\\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong number of layers. Expected 3 but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(target\u001B[38;5;241m.\u001B[39mlayers)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mas_list() \u001B[38;5;241m==\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m400\u001B[39m], \\\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong input shape. Expected [None,  400] but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39minput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mas_list()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     12\u001B[0m     i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     13\u001B[0m     expected \u001B[38;5;241m=\u001B[39m [[Dense, [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m25\u001B[39m], sigmoid],\n\u001B[0;32m     14\u001B[0m                 [Dense, [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m15\u001B[39m], sigmoid],\n\u001B[0;32m     15\u001B[0m                 [Dense, [\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m1\u001B[39m], sigmoid]]\n",
      "File \u001B[1;32mD:\\SoftWare\\anaconda3\\envs\\pytorchenv4learn\\lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001B[0m, in \u001B[0;36mOperation.input\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minput\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    246\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \n\u001B[0;32m    248\u001B[0m \u001B[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;124;03m        Input tensor or list of input tensors.\u001B[39;00m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_node_attribute_at_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_tensors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\SoftWare\\anaconda3\\envs\\pytorchenv4learn\\lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001B[0m, in \u001B[0;36mOperation._get_node_attribute_at_index\u001B[1;34m(self, node_index, attr, attr_name)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \n\u001B[0;32m    271\u001B[0m \u001B[38;5;124;03mThis is used to implement the properties:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    282\u001B[0m \u001B[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001B[39;00m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes:\n\u001B[1;32m--> 285\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    286\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe layer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has never been called \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    287\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand thus has no defined \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    288\u001B[0m     )\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes) \u001B[38;5;241m>\u001B[39m node_index:\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    291\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsked to get \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m at node \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    292\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnode_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but the operation has only \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    293\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m inbound nodes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    294\u001B[0m     )\n",
      "\u001B[1;31mAttributeError\u001B[0m: The layer my_model has never been called and thus has no defined input."
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter counts shown in the summary correspond to the number of elements in the weight and bias arrays as shown below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "L1_num_params = 400 * 25 + 25  # W1 parameters  + b1 parameters\n",
    "L2_num_params = 25 * 15 + 15   # W2 parameters  + b2 parameters\n",
    "L3_num_params = 15 * 1 + 1     # W3 parameters  + b3 parameters\n",
    "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params, \",  L3 params = \", L3_num_params )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further examine the weights to verify that tensorflow produced the same dimensions as we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "```\n",
    "W1 shape = (400, 25), b1 shape = (25,)  \n",
    "W2 shape = (25, 15), b2 shape = (15,)  \n",
    "W3 shape = (15, 1), b3 shape = (1,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xx.get_weights` returns a NumPy array. One can also access the weights directly in their tensor form. Note the shape of the tensors in the final layer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(model.layers[2].weights)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will define a loss function and run gradient descent to fit the weights of the model to the training data. This will be explained in more detail in the following week."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X,y,\n",
    "    epochs=20\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model on an example to make a prediction, use [Keras `predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model). The input to `predict` is an array so the single example is reshaped to be two dimensional."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prediction = model.predict(X[0].reshape(1,400))  # a zero\n",
    "print(f\" predicting a zero: {prediction}\")\n",
    "prediction = model.predict(X[500].reshape(1,400))  # a one\n",
    "print(f\" predicting a one:  {prediction}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model is interpreted as a probability. In the first example above, the input is a zero. The model predicts the probability that the input is a one is nearly zero. \n",
    "In the second example, the input is a one. The model predicts the probability that the input is a one is nearly one.\n",
    "As in the case of logistic regression, the probability is compared to a threshold to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(f\"prediction after threshold: {yhat}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the predictions vs the labels for a random sample of 64 digits. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Predict using the Neural Network\n",
    "    prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    if prediction >= 0.5:\n",
    "        yhat = 1\n",
    "    else:\n",
    "        yhat = 0\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index,0]},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 NumPy Model Implementation (Forward Prop in NumPy)\n",
    "As described in lecture, it is possible to build your own dense layer using NumPy. This can then be utilized to build a multi-layer neural network. \n",
    "\n",
    "<img src=\"images/C2_W1_dense2.PNG\" width=\"600\" height=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "Below, build a dense layer subroutine. The example in lecture utilized a for loop to visit each unit (`j`) in the layer and perform the dot product of the weights for that unit (`W[:,j]`) and sum the bias for the unit (`b[j]`) to form `z`. An activation function `g(z)` is then applied to that result. This section will not utilize some of the matrix operations described in the optional lectures. These will be explored in a later section."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: my_dense\n",
    "\n",
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "### START CODE HERE ### \n",
    "    for i in range(units):\n",
    "        w = W[:,i]\n",
    "        z=np.dot(w,a_in) + b[i]\n",
    "        a_out[i]=g(z)\n",
    "### END CODE HERE ### \n",
    "    return(a_out)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Quick Check\n",
    "x_tst = 0.1*np.arange(1,3,1).reshape(2,)  # (1 examples, 2 features)\n",
    "W_tst = 0.1*np.arange(1,7,1).reshape(2,3) # (2 input features, 3 output features)\n",
    "b_tst = 0.1*np.arange(1,4,1).reshape(3,)  # (3 features)\n",
    "A_tst = my_dense(x_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "```\n",
    "[0.54735762 0.57932425 0.61063923]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "As described in the lecture:\n",
    "    \n",
    "```python\n",
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):             \n",
    "        w =                            # Select weights for unit j. These are in column j of W\n",
    "        z =                            # dot product of w and a_in + b\n",
    "        a_out[j] =                     # apply activation to z\n",
    "    return(a_out)\n",
    "```\n",
    "   \n",
    "    \n",
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for more hints</b></font></summary>\n",
    "\n",
    "    \n",
    "```python\n",
    "def my_dense(a_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):             \n",
    "        w = W[:,j]                     \n",
    "        z = np.dot(w, a_in) + b[j]     \n",
    "        a_out[j] = g(z)                \n",
    "    return(a_out)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNIT TESTS\n",
    "test_c2(my_dense)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds a three-layer neural network utilizing the `my_dense` subroutine above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def my_sequential(x, W1, b1, W2, b2, W3, b3):\n",
    "    a1 = my_dense(x,  W1, b1, sigmoid)\n",
    "    a2 = my_dense(a1, W2, b2, sigmoid)\n",
    "    a3 = my_dense(a2, W3, b3, sigmoid)\n",
    "    return(a3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy trained weights and biases from Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "W1_tmp,b1_tmp = layer1.get_weights()\n",
    "W2_tmp,b2_tmp = layer2.get_weights()\n",
    "W3_tmp,b3_tmp = layer3.get_weights()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# make predictions\n",
    "prediction = my_sequential(X[0], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[0,0])\n",
    "prediction = my_sequential(X[500], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[500,0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see predictions from both the Numpy model and the Tensorflow model. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    # Predict using the Neural Network implemented in Numpy\n",
    "    my_prediction = my_sequential(X[random_index], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "    my_yhat = int(my_prediction >= 0.5)\n",
    "\n",
    "    # Predict using the Neural Network implemented in Tensorflow\n",
    "    tf_prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    tf_yhat = int(tf_prediction >= 0.5)\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index,0]},{tf_yhat},{my_yhat}\")\n",
    "    ax.set_axis_off() \n",
    "fig.suptitle(\"Label, yhat Tensorflow, yhat Numpy\", fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Vectorized NumPy Model Implementation (Optional)\n",
    "The optional lectures described vector and matrix operations that can be used to speed the calculations.\n",
    "Below describes a layer operation that computes the output for all units in a layer on a given input example:\n",
    "\n",
    "<img src=\"images/C2_W1_VectorMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "We can demonstrate this using the examples `X` and the `W1`,`b1` parameters above. We use `np.matmul` to perform the matrix multiply. Note, the dimensions of x and W must be compatible as shown in the diagram above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = X[0].reshape(-1,1)         # column vector (400,1)\n",
    "z1 = np.matmul(x.T,W1) + b1    # (1,400)(400,25) = (1,25)\n",
    "a1 = sigmoid(z1)\n",
    "print(a1.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take this a step further and compute all the units for all examples in one Matrix-Matrix operation.\n",
    "\n",
    "<img src=\"images/C2_W1_MatrixMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "The full operation is $\\mathbf{Z}=\\mathbf{XW}+\\mathbf{b}$. This will utilize NumPy broadcasting to expand $\\mathbf{b}$ to $m$ rows. If this is unfamiliar, a short tutorial is provided at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex03\"></a>\n",
    "### Exercise 3\n",
    "\n",
    "Below, compose a new `my_dense_v` subroutine that performs the layer calculations for a matrix of examples. This will utilize `np.matmul()`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: my_dense_v\n",
    "\n",
    "def my_dense_v(A_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      A_in (ndarray (m,n)) : Data, m examples, n features each\n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (1,j)) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      A_out (ndarray (m,j)) : m examples, j units\n",
    "    \"\"\"\n",
    "### START CODE HERE ### \n",
    "    A_out = g(np.matmul(A_in,W) + b)\n",
    "    \n",
    "### END CODE HERE ### \n",
    "    return(A_out)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_tst = 0.1*np.arange(1,9,1).reshape(4,2) # (4 examples, 2 features)\n",
    "W_tst = 0.1*np.arange(1,7,1).reshape(2,3) # (2 input features, 3 output features)\n",
    "b_tst = 0.1*np.arange(1,4,1).reshape(1,3) # (1, 3 features)\n",
    "A_tst = my_dense_v(X_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "```\n",
    "[[0.54735762 0.57932425 0.61063923]\n",
    " [0.57199613 0.61301418 0.65248946]\n",
    " [0.5962827  0.64565631 0.6921095 ]\n",
    " [0.62010643 0.67699586 0.72908792]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    In matrix form, this can be written in one or two lines. \n",
    "    \n",
    "       Z = np.matmul of A_in and W plus b    \n",
    "       A_out is g(Z)  \n",
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for code</b></font></summary>\n",
    "\n",
    "```python\n",
    "def my_dense_v(A_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      A_in (ndarray (m,n)) : Data, m examples, n features each\n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j,1)) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      A_out (ndarray (m,j)) : m examples, j units\n",
    "    \"\"\"\n",
    "    Z = np.matmul(A_in,W) + b    \n",
    "    A_out = g(Z)                 \n",
    "    return(A_out)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNIT TESTS\n",
    "test_c3(my_dense_v)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell builds a three-layer neural network utilizing the `my_dense_v` subroutine above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
    "    A1 = my_dense_v(X,  W1, b1, sigmoid)\n",
    "    A2 = my_dense_v(A1, W2, b2, sigmoid)\n",
    "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
    "    return(A3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again copy trained weights and biases from Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "W1_tmp,b1_tmp = layer1.get_weights()\n",
    "W2_tmp,b2_tmp = layer2.get_weights()\n",
    "W3_tmp,b3_tmp = layer3.get_weights()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction with the new model. This will make a prediction on *all of the examples at once*. Note the shape of the output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
    "Prediction.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply a threshold of 0.5 as before, but to all predictions at once."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Yhat = (Prediction >= 0.5).numpy().astype(int)\n",
    "print(\"predict a zero: \",Yhat[0], \"predict a one: \", Yhat[500])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see predictions. This will use the predictions we just calculated above. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "   \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index,0]}, {Yhat[random_index, 0]}\")\n",
    "    ax.set_axis_off() \n",
    "fig.suptitle(\"Label, Yhat\", fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how one of the misclassified images looks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(1, 1))\n",
    "errors = np.where(y != Yhat)\n",
    "random_index = errors[0][0]\n",
    "X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "plt.imshow(X_random_reshaped, cmap='gray')\n",
    "plt.title(f\"{y[random_index,0]}, {Yhat[random_index, 0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.7\"></a>\n",
    "### 2.7 Congratulations!\n",
    "You have successfully built and utilized a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.8\"></a>\n",
    "### 2.8 NumPy Broadcasting Tutorial (Optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the last example,  $\\mathbf{Z}=\\mathbf{XW} + \\mathbf{b}$ utilized NumPy broadcasting to expand the vector $\\mathbf{b}$. If you are not familiar with NumPy Broadcasting, this short tutorial is provided.\n",
    "\n",
    "$\\mathbf{XW}$  is a matrix-matrix operation with dimensions $(m,j_1)(j_1,j_2)$ which results in a matrix with dimension  $(m,j_2)$. To that, we add a vector $\\mathbf{b}$ with dimension $(1,j_2)$.  $\\mathbf{b}$ must be expanded to be a $(m,j_2)$ matrix for this element-wise operation to make sense. This expansion is accomplished for you by NumPy broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting applies to element-wise operations.  \n",
    "Its basic operation is to 'stretch' a smaller dimension by replicating elements to match a larger dimension.\n",
    "\n",
    "More [specifically](https://NumPy.org/doc/stable/user/basics.broadcasting.html): \n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\n",
    "- they are equal, or\n",
    "- one of them is 1   \n",
    "\n",
    "If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center> <img src=\"./images/C2_W1_Assign1_BroadcastIndexes.PNG\"  alt='missing' width=\"400\"  ><center/>\n",
    "    <figcaption>Calculating Broadcast Result shape</figcaption>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphic below describes expanding dimensions. Note the red text below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center> <img src=\"./images/C2_W1_Assign1_Broadcasting.gif\"  alt='missing' width=\"600\"  ><center/>\n",
    "    <figcaption>Broadcast notionally expands arguments to match for element wise operations</figcaption>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphic above shows NumPy expanding the arguments to match before the final operation. Note that this is a notional description. The actual mechanics of NumPy operation choose the most efficient implementation.\n",
    "\n",
    "For each of the following examples, try to guess the size of the result before running the example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this applies to all element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a * b).shape: {(a * b).shape}, \\na * b = \\n{a * b}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"./images/C2_W1_Assign1_VectorAdd.PNG\"  alt='missing' width=\"740\" >\n",
    "    <center><figcaption><b>Row-Column Element-Wise Operations</b></figcaption></center>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "a = np.array([1,2,3,4]).reshape(-1,1)\n",
    "b = np.array([1,2,3]).reshape(1,-1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the scenario in the dense layer you built above. Adding a 1-D vector $b$ to a (m,j) matrix.\n",
    "<figure>\n",
    "    <img src=\"./images/C2_W1_Assign1_BroadcastMatrix.PNG\"  alt='missing' width=\"740\" >\n",
    "    <center><figcaption><b>Matrix + 1-D Vector</b></figcaption></center>\n",
    "<figure/>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
